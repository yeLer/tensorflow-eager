{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to save and restore a trained model\n",
    "\n",
    "After scrolling through the posts of [reddit.com/r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning/), I've realized that the major bottlenecks of a machine learning project occur in the data input pipeline and in the final stage of the model, where you have to save the model and make predictions on new data.\n",
    "So I thought that it would be useful to make a simple and straightforward tutorial to show you how you could save and restore a model that you have built with Tensorflow Eager.\n",
    "\n",
    "### Tutorial flowchart\n",
    "----\n",
    "\n",
    "![img](tutorials_graphics/save_restore_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import here useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow and TensorFlow Eager\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "# Import function to generate toy classication problem\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable eager mode. Once activated it cannot be reversed! Run just once.\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Build a simple neural network model for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simple_nn(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(simple_nn, self).__init__()\n",
    "        \"\"\" Define here the layers used during the forward-pass \n",
    "            of the neural network.\n",
    "        \"\"\"   \n",
    "        # Hidden layer.\n",
    "        self.dense_layer = tf.layers.Dense(10, activation=tf.nn.relu)\n",
    "        # Output layer. No activation.\n",
    "        self.output_layer = tf.layers.Dense(2, activation=None)\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        \"\"\" Runs a forward-pass through the network.     \n",
    "            Args:\n",
    "                input_data: 2D tensor of shape (n_samples, n_features).   \n",
    "            Returns:\n",
    "                logits: unnormalized predictions.\n",
    "        \"\"\"\n",
    "        hidden_activations = self.dense_layer(input_data)\n",
    "        logits = self.output_layer(hidden_activations)\n",
    "        return logits\n",
    "    \n",
    "    def loss_fn(self, input_data, target):\n",
    "        \"\"\" Defines the loss function used during \n",
    "            training.         \n",
    "        \"\"\"\n",
    "        logits = self.predict(input_data)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=target, logits=logits)\n",
    "        return loss\n",
    "    \n",
    "    def grads_fn(self, input_data, target):\n",
    "        \"\"\" Dynamically computes the gradients of the loss value\n",
    "            with respect to the parameters of the model, in each\n",
    "            forward pass.\n",
    "        \"\"\"\n",
    "        with tfe.GradientTape() as tape:\n",
    "            loss = self.loss_fn(input_data, target)\n",
    "        return tape.gradient(loss, self.variables)\n",
    "    \n",
    "    def fit(self, input_data, target, optimizer, num_epochs=500, verbose=50):\n",
    "        \"\"\" Function to train the model, using the selected optimizer and\n",
    "            for the desired number of epochs.\n",
    "        \"\"\"\n",
    "        for i in range(num_epochs):\n",
    "            grads = self.grads_fn(input_data, target)\n",
    "            optimizer.apply_gradients(zip(grads, self.variables))\n",
    "            if (i==0) | ((i+1)%verbose==0):\n",
    "                print('Loss at epoch %d: %f' %(i+1, self.loss_fn(input_data, target).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate toy dataset for classification\n",
    "# X is a matrix of n_samples x n_features and represents the input features\n",
    "# y is a vector with length n_samples and represents our targets\n",
    "X, y = make_moons(n_samples=100, noise=0.1, random_state=2018)\n",
    "X_train, y_train = tf.constant(X[:80,:]), tf.constant(y[:80])\n",
    "X_test, y_test = tf.constant(X[80:,:]), tf.constant(y[80:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.663213\n",
      "Loss at epoch 50: 0.260983\n",
      "Loss at epoch 100: 0.248480\n",
      "Loss at epoch 150: 0.245092\n",
      "Loss at epoch 200: 0.240079\n",
      "Loss at epoch 250: 0.227281\n",
      "Loss at epoch 300: 0.196819\n",
      "Loss at epoch 350: 0.153906\n",
      "Loss at epoch 400: 0.113223\n",
      "Loss at epoch 450: 0.083055\n",
      "Loss at epoch 500: 0.061716\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(5e-1)\n",
    "model = simple_nn()\n",
    "model.fit(X_train, y_train, optimizer, num_epochs=500, verbose=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify checkpoint directory\n",
    "checkpoint_directory = 'models_checkpoints/SimpleNN/'\n",
    "# Create model checkpoint\n",
    "checkpoint = tfe.Checkpoint(optimizer=optimizer,\n",
    "                            model=model,\n",
    "                            optimizer_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models_checkpoints/SimpleNN/-1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model\n",
    "checkpoint.save(file_prefix=checkpoint_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Restore trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reinitialize model instance\n",
    "model = simple_nn()\n",
    "optimizer = tf.train.GradientDescentOptimizer(5e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify checkpoint directory\n",
    "checkpoint_directory = 'models_checkpoints/SimpleNN/'\n",
    "# Create model checkpoint\n",
    "checkpoint = tfe.Checkpoint(optimizer=optimizer,\n",
    "                            model=model,\n",
    "                            optimizer_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fbfbe8b0ac8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore model from latest chekpoint\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Check if the model was restored correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.061338\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, optimizer, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss seems to be consistent with the loss we obtained in the last epoch of previous training :)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VI: Make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.46661161 -0.81602877]\n",
      " [-2.69060157  1.23526029]\n",
      " [ 2.43001643 -2.35215769]\n",
      " [-2.86877127  0.42311112]\n",
      " [ 0.68118177 -0.80872488]\n",
      " [ 2.36590208 -2.16004146]\n",
      " [-2.80039488  2.21221565]\n",
      " [-3.16031675  0.71963893]\n",
      " [-2.76745803  0.67758663]\n",
      " [ 2.6786072  -2.55252435]\n",
      " [-1.11169555  0.52728788]\n",
      " [-3.76186803  1.23969049]\n",
      " [-2.98417084  0.51195994]\n",
      " [ 0.46995946 -0.60803168]\n",
      " [ 1.27858134 -1.52766214]\n",
      " [ 1.53762815 -1.62909484]\n",
      " [ 2.75608972 -2.49590808]\n",
      " [ 0.92804539 -1.04823756]\n",
      " [ 1.93477522 -2.09747617]\n",
      " [-2.98634282  0.35103911]], shape=(20, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(logits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
